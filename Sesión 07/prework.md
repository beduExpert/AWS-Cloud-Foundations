# Prework

# Introducci칩n
Hay varios t칩picos en AWS m치s avanzados, los anteriores fueron los bloques fundamentales que toda la nube de AWS est치 construida. 
T칩picos avanzados de AWS se construyen y manejan sobre los t칩picos b치sicos, se dar치 por hecho que los t칩picos b치sicos se conocen por lo que no se profundizar치 en ellos al ser mencionados.


# 1. Objetivo 游꿢
- Conocer las herramientas para desarrolladores de AWS.
- Conocer como las mejores pr치cticas en el entorno AWS encajan y son consistentes a lo largo de los servicios.

# 2. Instrucciones 游늶
- Se debe leer el contenido en un ambiente libre de distractores f칤sicos y electr칩nicos atendiendo a los enlaces en el texto.

# 3. Desarrollo 游늼

# AWS Developer Tools

La forma de desarrollo de software que a칰n es com칰n implica que los cambios de software se trabajen de manera aislada por periodos largos de tiempo, despu칠s de algunos d칤as se trata de combinar y desplegar c칩digo a producci칩n lo que resulta dif칤cil con probabilidad alta de inserci칩n de errores lo que provoca malestar y desconfianza por parte de los clientes, eso sin contar con la lentitud ante cambios de requerimientos.

El flujo de integraci칩n continua de c칩digo es una pr치ctica de desarrollo de software en la que a cada cambio de en el repositorio central se construyen paquetes de c칩digo desplegados ejecutando pruebas autom치ticas tradicionalmente `unit testing`, si la etapa de testing falla el paquete con c칩digo no pasa a ser desplegado a producci칩n, la idea es detectar fallos en etapas tempranas en el desarrollo de software.


La integraci칩n continua se conforma de una fase de creaci칩n y pruebas unitarias del proceso de publicaci칩n de software. Cada commit enviado al repositorio activa autom치ticamente la creaci칩n y las pruebas.
![code-deploy-pipeline-01.png](code-deploy-pipeline-01.png)

AWS cuenta con herramientas para implantar los flujos de integraci칩n continua, para la fase source se cuenta con CodeCommit, para construir el entregable  (build) se tiene CodeBuild, para desplegar a producci칩n CodeDeploy har치 el trabajo, finalmente para orquestar todas las etapas se tiene a CodePipeline.

- CodeCommit: Es un control de versiones de software compatible con Git, es totalmente administrado por lo que no hay que preocuparse de servidores, es similar a otros proveedores de control de versiones de c칩digo administrados como Bit Bucket o GitHub, la ventaja es que se integra bien con varios servicios de AWS para facilitar tareas de desarrollo de software entre ellos cifrado de repositorios con AWS Key Management Service (KMS) y AWS IAM para el control de acceso a los mismos.

![code-build-integracion-sevicios-01.png](code-build-integracion-sevicios-01.png)

- CodeBuild: 
Encargado de la compilaci칩n de c칩digo fuente y ejecuci칩n de pruebas, produce paquetes de software listos para ser ejecutados.
Cuenta con soporte para S3, Github y Bitbucket como or칤genes de c칩digo.
Se debe especificar  el origen c칩digo fuente y el entorno de compilaci칩n, junto con otras especificaciones de compilaci칩n en un archivo buildspec.yml , AWS aprovisionar치 autom치ticamente un entorno aislado basado en contenedores para ejecutar la compilaci칩n. En contenedor puede ser un contenedor administrado y mantenido por AWS aunque tambi칠n es posible utilizar contenedores propietarios o de terceros.
La variedad de contenedores que pueden ser usados abre la puerta a soporte para c칩digo escrito en Android, Java, Python, Ruby, Go y un largo etc칠tera, todo depender치 de lo que pueda soportar Docker.
La forma de cobro de CodeBuild es costo por minuto medido desde que se lanza el contenedor para comenzar con el testeo y se finaliza construcci칩n de un paquete de software. 
Es posible integrar webhooks a CodeBuild, imaginar mandar un commit al repositorio, se ejecutan los test, y en caso de falla CodeBuild puede avisar en un canal de [Slack o levantar un ticket en Jira sobre el problema](https://github.com/aws-samples/aws-codebuild-webhooks).

- CodeDeploy:
Es necesario despu칠s de generar un paquete de software ya testeado implementar o desplegar en un entorno de ejecuci칩n para ser usado. CodeDeploy soporta despliegue de software en instancias EC2, Lambda, servidores locales y claro Contenedores de Docker. Con esto es posible automatizar los despliegues que antes deb칤an ser de forma manual, en entornos de producci칩n puede que no quite mucho tiempo pero para entornos de desarrollo donde continuamente se liberan nuevos cambios o features la distracci칩n para quien se encargaba del despliegue se vuelve representativo en la productividad del d칤a a d칤a.
CodeDeploy puede desplegar c칩digo en cualquier lenguaje de programaci칩n, lo 칰nico que hay que hacer es especificar una secuencia de comandos para el despliegue en un archivo AppSpec en formato YAML. CodeDeploy se basa en la instalaci칩n de un agente en los servidores a desplegar por lo que ademas de soportar despliegues para Amazon Linux, Red Hat Enterprise Linux, Ubuntu Server y  Windows Server  se puede usar en otros sistemas operativos compilando e instalando el agente en ellos.
En cuanto a precios, no hay costos asociados en los despliegues hechos en EC2, ECS o Lambda, solo hay costo si es un despliegue local.

-CodePipeline
Finalmente la orquestaci칩n e integraci칩n de todas estas etapas se vuelve un factor clave para el 칠xito de una estrategia de entrega continua de c칩digo. Con CodePipeline se define un flujo de entrega de software en mira de minimizar el tedioso trabajo de construcci칩n de desplegables, testing y despliegue y con ello tambi칠n el error humano. Todos los pasos son altamente configurables por la Consola de AWS, API, SDK, AWS CLI y CloudFormation, especialmente interesante AWS CLI y CloudFormation por sus capacidades de automatizaci칩n.
CodePipeline no queda relegado a trabajar con servicios de AWS, tambi칠n se integra bien con Github, Jenkins o TeamCity, BlazeMeter, Ghost Inspector entre otros.


# Alta disponibilidad  y Tolerancia a fallas
En entornos productivos sistemas fiables, tolerantes a fallos y altamente disponibles son altamente apreciados, que ganan la confianza de los clientes y deriva normalmente en mejores ganancias para las organizaciones. Ning칰n sistema en la actualidad esta libre de errores, incluso gigantes con todo el poder econ칩mico, infraestructura y de talento humano como [YouTube](https://twitter.com/YouTubeEspanol/status/1326687906291998721) puede fallar.
Hist칩ricamente lograr estos objetivos requer칤a especialistas con buena experiencia, adquisici칩n de hardware y software, acondicionamiento, m칰ltiples centros de datos (muchas veces inviables econ칩micamente), hoy d칤a con la explosi칩n de la oferta de c칩mputo en la nube es relativamente sencillo conseguir aplicaciones con niveles de disponibilidad pr치cticamente a la par de empresas l칤deres en el sector.
La propia distribuci칩n de las regiones y zonas de disponibilidad de AWS proporciona facilidad para despliegue en zonas geogr치ficas distintas sin sacrificar la cercan칤a de las soluciones al usuario final. El servicio ELB es clave en la estrategia de distribuci칩n de tr치fico hacia distintas zonas de disponibilidad dando pie al dise침o de arquitecturas resistentes a fallas (pasivas) o tr치fico intensivo (activas). 
La replicaci칩n y generaci칩n de clusters de base de datos con el servicio RDS libera a los administradores de las tareas de configuraci칩n, es f치cil generar un servicio de base de datos con r칠plica en 3 distintas zonas de disponibilidad con capacidad de redirecci칩n de tr치fico en caso de que uno de los nodos del cluster falle.
La etapa de servidores es igualmente f치cil de escalar, el servicio EC2 se integra f치cilmente con ELB para tolerancia ante fallas, con el advenimiento de contenedores Docker es a칰n m치s sencillo generar arquitecturas altamente tolerantes a fallos por la propia naturaleza autocontenida de toda la configuraci칩n necesaria para que una aplicaci칩n funcione, en AWS se hace uso de servicios como ELK o ECS.
Otros servicios totalmente administrados de AWS como SQS, SES, Lambda, S3, VPC, Toda la suite de Macchinne Learning, API Gateway y una larga lista de otros servicios indudablemente con los niveles de servicios que ofrecen podemos tener certeza que las arquitecturas dise침adas pr치cticamente no tendr치n puntos 칰nicos de falla.

# Arquitectura de datos
Al hablar de arquitectura de datos las primeras preguntas que se deben responder para seleccionar la mejor estrategia son:
* 쯈u칠 tal grande es el set de datos a procesar?
* 쮺u치l es la tasa de crecimiento del set de datos?
* 쯃os datos son estructurados o no estructurados?
* 쮼s realmente redituable para la organizaci칩n procesar los datos (oferta de valor)? 
* 쯃os resultados se esperan en tiempo real, en horas, en d칤as?
* 쮺u치l es el costo par ael negocio no llegar a contar con los resultados del procesamiento de los datos?
* 쯈ue necesidades de integraci칩n entre quien produce los datos y requiere de la informaci칩n resultante son requeridas?

- Amazon EMR:
Es el servicio de AWS para procesamiento distribuido de lagos data sets procesando a trav칠s de clusters din치micos de instancias EC2 compatible con el ecosistema de Hadoop, herramientas como Spark, Hive, MapReduce, Apache HCatalog, Apache Pig estar치n a disposici칩n. ERM pondr치 a disposici칩n el procesamiento pero igualmente importante  servicio de anal칤tica. Lo atractivo de EMR es que se encarga del mantenimiento y manejo del cluster de Hadoop, el escalado autom치tico es muy importante en este tipo de soluciones de cluster a la hora de aminorar costos asociados a los nodos del mismo.

쮸 que se hace referencia al hablar de distribuci칩n?, bien EMR se encarga de reducir sets de datos a ser procesados en trabajos peque침os a trav칠s de las m칰ltiples unidades de c칩mputo que conforman el cluster, las tareas pueden tener relaci칩n  con trabajos de  [ETL](https://www.coursera.org/lecture/clinical-data-models-and-data-quality-assessments/the-etl-task-U2ZUR) , procesamiento de logs, forecasting, [bioinformatics](https://www.genome.gov/genetics-glossary/Bioinformatics), [deep learning](https://machinelearningmastery.com/what-is-deep-learning/), [simulaciones cient칤ficas](https://home.cern/science/computing/processing-what-record), [an치lisis financiero](https://corporatefinanceinstitute.com/resources/knowledge/finance/types-of-financial-analysis/) por mencionar algunas.

Se puede tener mucha informaci칩n sensible en el cluster EMR por lo que la seguridad es cr칤tica, para solventar la necesidad EMR se integra bien con IAM, Cloud Trail, VPC, AWS Key Management Service y los grupos de seguridad de las instancias EC2.

EMR no es recomendado en sets de datos peque침os, es decir en sets de datos que pueden f치cilmente ser procesados en memoria en una sola instancia, no se recomienda para tareas que requieran transacciones [ACID](https://www.ibm.com/support/knowledgecenter/SSGMCP_5.4.0/product-overview/acid.html).

- Amazon Elasticsearch Service
Elasticsearch es el servicio de log analytics por excelencia, Elasticsearch funciona en modo cluster en producci칩n por lo que poner a punto un cluster puede llegar a ser retador. Amazon Elastic Service quita esa complejidad de los hombros del administrador al ser un servicio totalmente administrado.
Casos de uso son log analytics, b칰squeda en textos, monitoreo de aplicaciones web, monitoreo de eventos como clicks, visualizaci칩n de datos, combinaci칩n de informaci칩n y an치lisis, an치lisis de datos en stream, monitoreo de aplicaciones m칩viles. 쯈ui칠n se imaginar칤a que [Tinder](https://www.elastic.co/es/elasticon/conf/2017/sf/tinder-using-the-elastic-stack-to-make-connections-around-the-world) en su n칰cleo no es m치s que un motor de b칰squeda?, aunque no hay que demeritar, las necesidades de b칰squeda contemplan 50 lenguajes y multitud de par치metros de cada persona millones de veces al d칤a.

El servicio es provisto bajo el modelo paga lo que usa, dependiendo del tipo y tama침o de las instancias que conforman al cluster ser치 el precio a pagar a final de mes, se pueden optar por instancias peque침as si es que el precio es un problema o si se esta haciendo una prueba de concepto.
La integraci칩n con otros servicios hace atractivo el uso de Elasticsearch Service, va bien con las herramientas Kibana y Logstash propias del ecosistema de Elasticsearch, aunque se puede integrar bien con los servicios Kinesis Firehose, AWS Lambda y cloudwatch.

En general Elasticsearch no se lleva bien con transacciones ACID.

- Amazon QuickSight
El servicio de Business Intelligence de tipo serverless, no hay que desplegar infraestructura, no hay que mantener infraestructura.

Como servicio de BI se requiere una fuente de datos para presentar los dashboard, se puede conectar con AWS Athena,  Redshift, subir archivos csb, tsv, xlsx, json o conectarse a un Bucket S3 para extraer los datos de 칠l recordando que un bucket S3 puede ser usado como un data lake se puede conectar a redes VPC privadas lo que abre la posibilidad de conectar con bases de datos que se conecten a esas redes en una instancia EC2 de tipo Postgres o MySQL o en todo caso conectar con una instancia de RDS. 
A continuaci칩n una vista de las distintas fuentes de datos soportadas.
![prework-fiuentes-de-datos-01.png](prework-fiuentes-de-datos-01.png)

![prework-quick-sigth-fuentes-datos-02.png](prework-quick-sigth-fuentes-datos-02.png)


Una caracter칤stica muy atractiva es que se puede construir el dashboard e insertar (embedding) dentro de las aplicaciones. Como desventaja es que para que esto funcione habr치 que hacer que los usuarios finales se autentiquen por OpenID, SAML o Cognito, aunque considerando que los dashboards a vienen con drilldown y filtros realmente el ahorro de trabajo y mantenimiento puede tener sentido econ칩micamente hablando.

![prework-quick-sigth-01.png](prework-quick-sigth-01.png)

Cabe destacar que se pagan 30 centavos de d칩lar por cada usuario _reader_ que entre a ver el dashboard por 30 minutos con un m치ximo de 5 USD al mes esto para usuarios que son muy activos. Por otro lado se tienen a los usuarios _author_, por ellos se cobrar치 18 USD al mes si el autor se suscribe de manera anual, todo en este caso se refiere a los costos de la versi칩n Enterprise.
Actualmente se puede con herramientas de Machine learning para detecci칩n de anomal칤as, forecast y an치lisis de lenguaje natural (NLP), hay que tomar en cuenta que estas caracter칤sticas incurren a un costo extra al mostrado en la imagen.

Los siguientes son unos ejemplos de dashboards hechos con QuickSight. Hay que resaltar la cantidad de horas en desarrollo que hacer algo as칤 desde cero tomar칤a a un desarrollador o a varios hacer.

[Retail Analytics Powered by Ironside](https://d2lzvqq4w5ulk4.cloudfront.net/?dashboardName=retailSales)
[Hospital Predictive Profitability](https://d2lzvqq4w5ulk4.cloudfront.net/?dashboardName=healthcare)
[Thermostat Predictive Maintenance Records](https://d2lzvqq4w5ulk4.cloudfront.net/?dashboardName=iot)



- Amazon Glue
Glue es el servicio totalmente administrado de extracci칩n, transformaci칩n y carga (Extract-Transform-Load) de datos. Permite limpiar datos, filtrarlos, seleccionarlos y catalogarlos entre repositorios de informaci칩n. AWS Glue es catalogado como un servicio serverless, as칤 que no hay necesidad de manejar o provisionar  infraestructura. 
Glue se conecta con fuentes de datos como S3,  RDS, Redshift, JDBC, MongoDB y m치s, como destino S3 ser치 el servicio de preferencia.

Glue no esta dise침ado para trabajos con stream de datos, para un requerimiento as칤 existen opciones de la familia del servicio Kinesis, en todo caso lo que se puede hacer es guardar todo el stream de datos en un bucket S3 o en Redshift para despu칠s procesar los datos en batch con Glue.
Glue por el momento no es compatible con base de datos relacionales, las base de datos no relacionales carecen de un esquema por lo que hacer una tarea de ETL no esta soportada.



# AWS Well-architected Framework
Es un marco de buenas pr치cticas que ayuda a quienes dise침an soluciones en AWS a a crear aplicaciones resilientes, eficientes, de alto rendimiento con soporte a altas cargas de trabajo. 

Se basa en el cumplimiento de 5 pilares:

- Excelencia operativa:
* Se recomienda el uso de IaC (Infraestructura as Code) en pro automatizar la ejecuci칩n de tareas. 
* Hacer cambios peque침os en favor de poder hacer rollback con el menor impacto de esos cambios en caso de ser necesario. 
* Buscar continuamente oportunidades para mejorar procedimientos operativos.
* Anticiparse a fallos revisando peri칩dicamente el dise침o y el performance de la soluci칩n.
* Aprender de todos los incidentes haciendo retrospectiva una vez solucionados para que no se vuelvan a repetir.

- Seguridad:
* Toda aplicaci칩n deber칤a contar la aplicaci칩n del [principio del m칤nimo privilegio](https://www.securelink.com/blog/what-are-the-benefits-of-the-least-privileged-principle/) en todas las escalas de la aplicaci칩n, desde las redes VPC, balanceadores de carga hasta las instancias que ejecutan el aplicativo, IAM puede ayudar en esta tarea ofreciendo mecanismos de acceso granular a los servicios de AWS con credenciales fijas o temporales.
* La automatizaci칩n el clave para la reducci칩n de la brecha del error humano ya sea intencionado o no. Toda la suite de integraci칩n continua compuesta principalmente por CodeBuild, CodeBuild, CodeDeploy y CodePipeline es un buen ejemplo.
* Sin monitoreo se vuelve muy complicado dar tiempos de respuesta razonables ante una falla, degradamiento o intermitencia en el servicio ofrecido por la aplicaci칩n, siempre deber칤a existir una buena [observabilidad](https://youtu.be/fr1QvKg_6MU?list=PLZVwXPbHD1KMRRUApy-cVI7q6B5QhoF3H&t=1373) de todas las capas que componen al aplicaci칩n tanto de hardware como de software. Los servicios relacionados con monitoreo son CloudWatch, CloudTrail, y GuardDuty
* El cifrado de datos en tr치nsito y reposo con est치ndares de la industria como AES a fin de evitar [leaks de datos](https://twitter.com/luisitomx/status/444172249180811264).


- Fiabilidad:
* Cambios deben ser automatizados a fin de disminuir errores humanos, los cambios deben ser en c칩digo pero tambi칠n en infraestructura, AWS OpsWorks puede ayudar con la encomienda.
* Escalamiento horizontal basado en agregar nuevos recursos, es preferible manejar peque침os recursos que pueden ser a침adidos si la carga de trabajo lo requiere en lugar de usar un gran recurso. AWS Lambda va bien con este principio aunque EC2 con instancias peque침as balanceadas con ELB tambi칠n va bien. No olvidar RDS que puede ajustarse f치cilmente el tama침o de la instancia.
* Nunca basta con solo hacer backups, hay que hacer test que ellos funcionen, que se pueda recuperar la o las aplicaciones al 100% y que todo marche sobre ruedas, hay que recordar la historia de terror de GitLab por no hacer este procedimiento hace [algunos a침os](https://about.gitlab.com/blog/2017/02/01/gitlab-dot-com-database-incident/), el servicio de base de datos RDS y de c칩mputo EC2 cuentan con Snapshots como mecanismo b치sico de backups.
* La recuperaci칩n autom치tica ante una falla siempre debe ser preferencial a esperar a una recuperaci칩n manual, Route53 cuenta con estrategias de FailOver para redirigir tr치fico en caso de detectar ca칤da en un sitio, ELB tambi칠n tiene mecanismos para detectar la salud de los nodos que son balanceados a fin de reorganizar el algoritmo de redirecci칩n de tr치fico.
Todas las estrategias anteriores van enfocadas al aumento en la disponibilidad de los servicios ofrecidos medidos en tiempo de No disponibilidad al mes normalmente.
![prework-avalaibility-01.png](prework-avalaibility-01.png)


- Eficiencia de rendimiento:
* Afinidad mec치nica: Es necesario enfocarse en lo que requieren las soluciones y servicios a ofrecer para seleccionar la tecnolog칤a de AWS m치s acorde.
* Siempre probar, con las herramientas de automatizaci칩n de AWS es posible hacer pruebas comparativas con diferentes tipos de instancias, configuraci칩n y almacenamiento.
* Globalizar las aplicaciones siempre ser치 agradecido por los usuarios finales si es que est치n distribuidos alrededor del mundo.
* Considerar arquitecturas sin servidor a fin de eliminar la carga operativa que conlleva administrar instancias ante las cambiantes cargas de trabajo que se pueden presentar dependiendo la temporalidad.
* Algunas tecnolog칤as como machine learning demandan personal especializado, por lo que contar con servicios de AWS que quiten de los hombros a la empresa (sobre todo empresa en fase inicial de operaci칩n) hace que la tecnolog칤a especializada sea mas alcanzable.

- Optimizaci칩n de costos:
* Al igual que otros pilares, el ramo financiero debe tener atenci칩n a fin de tener un buen retorno de inversi칩n despu칠s de todo es esfuerzo implementado a lo largo de semanas en la implementaci칩n y mantenimiento de la soluci칩n a los clientes.
* Se ofrece en varios servicios pago por uso en horas, hay que aprovechar esta flexibilidad por ejemplo una instancia EC2 en desarrollo no es necesario que est칠 disponible las 24 horas del d칤a, se puede apagar fuera de horario laboral y fines de semana.
* Medir siempre lo que se gasta y en que se gasta da mucha claridad y la informaci칩n suficiente para emprender nuevas estrategias de venta y monetizaci칩n, AWS Cost Explorer  es ideal para esta tarea.
* Dejar de gastar en mantenimiento de infraestructura, operaciones, mantenimiento y personal puede ser beneficioso para la organizaci칩n. As칤 es m치s f치cil centrarse en clientes y proyectos en lugar de preocuparse por la infraestructura.



